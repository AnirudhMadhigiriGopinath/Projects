{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk, re, string, collections\n",
    "import regex as re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.util import ngrams \n",
    "from textblob import TextBlob\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "claimDataDF = pd.read_json('train-data-prepared.json')\n",
    "ValDataDF = pd.read_json('val-data-prepared.json')\n",
    "\n",
    "data = []\n",
    "valData = []\n",
    "just_text = \"\"\n",
    "mostCommon = \"\"\n",
    "\n",
    "def convertTuple(tup,words):\n",
    "    string =  \"\"\n",
    "    for i in range (words):\n",
    "        if i == words:\n",
    "            string =  string + str(tup[i])\n",
    "        else:\n",
    "            string =  string + str(tup[i]) + \" \"\n",
    "    return string\n",
    "def get_nouns(text):\n",
    "    blob = TextBlob(text)\n",
    "    nouns = [ word for (word,tag) in blob.tags if tag == \"NN\"]\n",
    "    return len(nouns)\n",
    "\n",
    "def convertTuple(tup,words):\n",
    "    string =  \"\"\n",
    "    for i in range (words):\n",
    "        if i == words:\n",
    "            string =  string + str(tup[i])\n",
    "        else:\n",
    "            string =  string + str(tup[i]) + \" \"\n",
    "    return string\n",
    "\n",
    "pattern = r'[,.+-\\\\/]'    \n",
    "for j in range(2):\n",
    "    dataF = claimDataDF\n",
    "    if j==1:\n",
    "        dataF = ValDataDF\n",
    "    for i in range(len(dataF)):    \n",
    "        currText = dataF.loc[i, \"text\"]\n",
    "        currText_lower = currText.lower()\n",
    "        sentResult = TextBlob(currText)\n",
    "        currText_lower = re.sub(pattern, '', currText_lower)\n",
    "        hasquestion = currText.find(\"?\")      \n",
    "        hasexclaimation = currText.find(\"!\") \n",
    "        hashash = currText.find(\"#\") \n",
    "        hasdollar = currText.find(\"$\") \n",
    "        hashttp = currText.find(\"http\")\n",
    "        hasamp = currText.find(\"&\")\n",
    "        wordCount = len(currText_lower)\n",
    "\n",
    "        firstspace =  False\n",
    "        if currText[0] == \" \":\n",
    "            firstspace = True\n",
    "\n",
    "        firstchar =  False\n",
    "        if re.search(pattern, currText[0]):\n",
    "            firstchar = True   \n",
    "\n",
    "        if(hasquestion>-1):\n",
    "            hasquestion = True\n",
    "        elif(hasquestion==-1):\n",
    "            hasquestion = False\n",
    "        if(hasexclaimation>-1):\n",
    "            hasexclaimation = True\n",
    "        elif(hasexclaimation==-1):\n",
    "            hasexclaimation = False\n",
    "        if(hashash>-1):\n",
    "            hashash = True\n",
    "        elif(hashash==-1):\n",
    "            hashash = False\n",
    "        if(hasdollar>-1):\n",
    "            hasdollar = True\n",
    "        elif(hasdollar==-1):\n",
    "            hasdollar = False\n",
    "        if(hashttp>-1):\n",
    "            hashttp = True\n",
    "        elif(hashttp==-1):\n",
    "            hashttp = False\n",
    "        if(hasamp>-1):\n",
    "            hasamp = True\n",
    "        elif(hasamp==-1):\n",
    "            hasamp = False       \n",
    "            \n",
    "        dataDict = {\"id\":dataF.loc[i, \"id\"], \n",
    "                    \"text\":dataF.loc[i, \"text\"], \n",
    "                    \"sentimentS\":sentResult.sentiment.subjectivity,\n",
    "                    \"charCount\":wordCount,\n",
    "                    \"startswithspace\":firstspace,\n",
    "                    \"startswithspchar\":firstchar,\n",
    "                    \"nouns\":get_nouns(currText_lower),\n",
    "                    \"hasquestion\":hasquestion,\n",
    "                    \"hasexclaimation\":hasexclaimation,\n",
    "                    \"hashash\":hashash,\n",
    "                    \"hasdollar\":hasdollar,\n",
    "                    \"hashttp\":hashttp,\n",
    "                    \"hasamp\":hasamp,\n",
    "                    \"label\":dataF.loc[i, \"label\"]\n",
    "                   }\n",
    "            \n",
    "        if j==0:\n",
    "            data.append(dataDict)\n",
    "        elif j==1:\n",
    "            valData.append(dataDict)\n",
    "\n",
    "trainDataDf = pd.DataFrame(data)   \n",
    "TestDataDF = pd.DataFrame(valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Txt = trainDataDf.copy()\n",
    "ValTxt = TestDataDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4chan</th>\n",
       "      <th>55</th>\n",
       "      <th>8710</th>\n",
       "      <th>able</th>\n",
       "      <th>abortions</th>\n",
       "      <th>about</th>\n",
       "      <th>actually</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>against</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>wouldn</th>\n",
       "      <th>wrong</th>\n",
       "      <th>www</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.66063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286777</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows Ã— 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     4chan   55  8710  able  abortions     about  actually  after  again  \\\n",
       "0      0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "1      0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "2      0.0  0.0   0.0   0.0        0.0  0.000000   0.66063    0.0    0.0   \n",
       "3      0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "4      0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "..     ...  ...   ...   ...        ...       ...       ...    ...    ...   \n",
       "344    0.0  0.0   0.0   0.0        0.0  0.286777   0.00000    0.0    0.0   \n",
       "345    0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "346    0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "347    0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "348    0.0  0.0   0.0   0.0        0.0  0.000000   0.00000    0.0    0.0   \n",
       "\n",
       "     against  ...  worth     would  wouldn  wrong  www  years  yes  you  your  \\\n",
       "0        0.0  ...    0.0  0.400249     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "1        0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "2        0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "3        0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "4        0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "..       ...  ...    ...       ...     ...    ...  ...    ...  ...  ...   ...   \n",
       "344      0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "345      0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "346      0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "347      0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "348      0.0  ...    0.0  0.000000     0.0    0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "     yourself  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "..        ...  \n",
       "344       0.0  \n",
       "345       0.0  \n",
       "346       0.0  \n",
       "347       0.0  \n",
       "348       0.0  \n",
       "\n",
       "[349 rows x 350 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = Txt['text']\n",
    "corpus1 = ValTxt['text']\n",
    "tfidf = TfidfVectorizer(max_features=350)\n",
    "X=tfidf.fit(corpus)\n",
    "Y = tfidf.transform(corpus)\n",
    "Txt2 = pd.DataFrame(Y.toarray(),columns =tfidf.get_feature_names())\n",
    "Txt2\n",
    "Z = tfidf.transform(corpus1) \n",
    "ValTxt2 = pd.DataFrame(Z.toarray(),columns =tfidf.get_feature_names())\n",
    "ValTxt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Txt.reset_index(drop=True, inplace=True)\n",
    "Txt2.reset_index(drop=True, inplace=True)\n",
    "ValTxt.reset_index(drop=True, inplace=True)\n",
    "ValTxt2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TxtClass = pd.concat([Txt,Txt2],axis=1)\n",
    "ValTxtClass = pd.concat([ValTxt,ValTxt2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TxtClass['word_count'] = TxtClass['text'].astype(str).str.replace(',','').str.split().str.len()\n",
    "ValTxtClass['word_count'] = ValTxtClass['text'].astype(str).str.replace(',','').str.split().str.len()\n",
    "x=TxtClass.copy()\n",
    "x=x.drop(columns=['id','text','label'])\n",
    "y=np.array(TxtClass.label).astype(int)\n",
    "\n",
    "xval=ValTxtClass.copy()\n",
    "xval=xval.drop(columns=['id','text','label'])\n",
    "yval=np.array(ValTxtClass.label).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759831996945399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non claim       0.72      0.85      0.78       223\n",
      "       Claim       0.61      0.41      0.49       126\n",
      "\n",
      "    accuracy                           0.69       349\n",
      "   macro avg       0.67      0.63      0.64       349\n",
      "weighted avg       0.68      0.69      0.68       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x,y)\n",
    "training_score=logreg.fit(x, y).score(x, y)\n",
    "print(training_score)\n",
    "y_pred = logreg.predict(xval)\n",
    "target_class= ['Non claim','Claim']\n",
    "print(classification_report(yval, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuned: {'C': 163789.3706954068}\n",
      "Best score is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non claim       0.74      0.82      0.78       223\n",
      "       Claim       0.60      0.49      0.54       126\n",
      "\n",
      "    accuracy                           0.70       349\n",
      "   macro avg       0.67      0.65      0.66       349\n",
      "weighted avg       0.69      0.70      0.69       349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "c = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c}\n",
    "logreg = LogisticRegression()\n",
    "lr = GridSearchCV(logreg, param_grid, cv = 5)  \n",
    "lr.fit(x, y)\n",
    "print(\"Hyperparameter tuned: {}\".format(lr.best_params_)) \n",
    "print(\"Best score is\".format(lr.best_score_))\n",
    "y_pred = lr.predict(xval)\n",
    "target_class= ['Non claim','Claim']\n",
    "print(classification_report(yval, y_pred, target_names=target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column= ['label']\n",
    "predictions = pd.DataFrame(data=y_pred,columns=column)\n",
    "predictions['id'] = ValTxt['id'].copy()\n",
    "predictions = predictions[['id','label']]\n",
    "Dict = {}\n",
    "for i in range(len(predictions)):\n",
    "    if predictions.loc[i, \"label\"] == 1:\n",
    "        val = 1\n",
    "    elif predictions.loc[i, \"label\"] == 0:\n",
    "        val = 0\n",
    "    Dict[predictions.loc[i, \"id\"]] = val\n",
    "    \n",
    "with open(\"predictions.json\", \"w\",) as outfile: \n",
    "    json.dump(Dict, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
